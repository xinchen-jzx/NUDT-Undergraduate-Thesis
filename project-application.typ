#import "project-application-template.typ": *

// Take a look at the file `template.typ` in the file panel
// to customize this template and discover how it works.
#show: project.with(
  title: "基于RISC-V存算一体芯片的编译器关键技术研究",
  name: "简泽鑫",
  idnum: "202102001019",
  major2: "无", 
  major1: "计算机科学与技术（计算机系统）", 
  college: "计算机学院",
  grade: "2021级", 
  advisor: "曾坤",
  jobtitle: "副研究员",
  unit: "计算机学院微电子与微处理器研究所", 
  comments: "本课题选题明确，具有较好的现实意义与创新性，制定的实施方案详实可行，文献调研充分，同意开题。"
)

#show math.equation: set text(font: "TeX Gyre Termes Math")

// #let continuous_table = state("continuous_table")
// #set table(stroke: (x, y) => {
//   if y == 0 {none} else {1pt}
// })
// #show table: it => continuous_table.update(false) + it

#show figure: it => {
    set text(size: 10.5pt)
    it
    v(-1em)
    box()
}
#show figure.where(kind: table): it => [
  #set figure.caption(position: top)
  #it
]

// We generated the example code below so you can see how
// your document will look. Go ahead and replace it with
// your own content!

= 课题名称、来源、选题依据

== 课题名称

基于RISC-V存算一体芯片的编译器关键技术研究

== 课题来源

源自老师自选课题

== 选题依据

随着人工智能（AI）和大数据应用的迅猛发展，计算需求呈指数级增长，传统的计算架构面临严峻挑战。特别是冯诺依曼架构由于其数据在存储和计算单元之间频繁传输，导致数据移动成为性能瓶颈，限制了系统的整体效率。为了解决这一问题，存算一体（Compute-In-Memory，CIM）架构应运而生，通过将计算功能集成到存储单元中，显著减少数据传输量，从而突破冯诺依曼瓶颈，提升系统性能和能效。

同时，RISC-V作为一种开放、可扩展的指令集架构（Instruction Set Architecture，ISA），凭借其完全开源、模块化设计和强大的可定制性，已成为构建存算一体芯片的首选。然而，基于RISC-V构建的存算芯片具有异构、碎片化的特点，这就要求开发者面向不同存算架构开发多个版本的应用，开发效率低、部署难。因此，如何实现将软件操作（包括计算、数据通信等）和硬件配置（如异构计算单元、存储层次等）解耦，以便AI应用开发不再依赖存算IP设计，是解决“编程墙”的关键问题。

不仅如此，AI应用的不规则的发展趋势和存算芯片的异构化、碎片化的现状，使得我们需要探索新的动态编译优化方法，这种优化方法既需要能够充分的考虑到AI应用的动态变化的特质，又需要能够充分的挖掘未来存算芯片的架构特征。通过动态编译优化，可以实时调整编译策略，使得生成的代码能够更好地适应硬件的运行环境，提高计算效率和资源利用率。

故，本课题将面向RISC-V存算芯片修改LLVM编译器，实现对存算指令的支持。通过深入研究LLVM编译器架构和工作原理，分析RISC-V存算一体芯片的特性，探索如何在LLVM中添加对RISC-V CIM的支持。这包括但不限于对指令集的扩展、内存模型的适配以及优化策略的调整等，以实现应用算子的自动映射和正确指令流的生成，从而更好地协调计算部件，挖掘芯片内部的计算并行性，为RISC-V存算一体芯片提供有力的编译支持。


= 国内外研究现状及发展趋势

== 国内外总体研究情况和发展前景

基于RISC-V指令集构建存算一体芯片逐渐成为AI加速器主流。一方面，RISC-V 指令集具有高度开放、标准化等优势，适合用领域定制的芯片开发和设计。另一方面，可以借助RISC-V国际社区的力量，通过RISC-V扩展标准化的推动和发展促进统一、高效的AI编程模型和系统软件支撑框架的形成。因此，谷歌、脸书、微软等巨头，都基于RISC-V指令集搭建自有AI芯片。2023年RISC-V SoC的市场渗透率达到2.6%，市场规模61亿美元，并正在持续上升。然而，人工智能深度领域定制的趋势导致了RISC-V存算一体芯片异构化、碎片化的特征。一方面，存算一体芯片本身具有异构性。芯片包含加速矩阵运算的张量核心以及加速向量计算的向量核心等加速部件。另一方面，虽然不同机构均基于RISC-V指令集进行芯片设计，但是不同机构的存算一体芯片具有迥异的架构特征，导致内部互联、存储器的存取方式等设计各不相同，造成了碎片化，给用户编程、程序优化带来了显著挑战，成为了当前人工智能芯片领域的国际性难题。

== 现有解决方案

为了解决上述问题，学术界和工业界提出了一系列的编译和编程解决方案。

- TVM @TVM18 是一个面向人工智能异构加速器的编译器框架，于2018年由华盛顿大学的研究团队发表。其以TensorFlow、PyTorch或ONNX等框架导入模型，将模型编译为可链接对象模块，然后轻量级TVM Runtime可以用C语言的API来动态加载模型，也可以为Python和Rust等其他语言提供入口点。在中间优化层级，其提出了Relay IR和Tensor IR两层中间表示来进行硬件无关（如常数折叠、算符融合等）、硬件相关（如计算模式识别与加速指令生成等）的优化。TVM可以自动为多种硬件生成优化代码，支持端到端的学习优化，并且具备灵活的编译流程，但是TVM在面对新型加速器时，不但需要开发者根据芯片指令去扩展TVM中的IR，还需要根据芯片的体系结构设计去添加定向优化策略，导致其扩展性较为有限。如 @TVM 所示。

#figure(
  image("./assets/TVM.png", width: 100%),
  caption: [
    TVM架构图
  ],
) <TVM>

- Triton @Triton19 主要用于加速深度学习应用在GPU上执行效率的编译器，于2021年由OpenAI发布。Triton是一种Python DSL，用于编写机器学习内核，支持多种硬件，包括CPU、GPU和ASIC等等，其能够生成针对特定硬件优化的内核。在中间优化层级，Triton编译器通过块级数据流分析技术，自动优化深度学习模型的执行过程。但是其主要面向英伟达和AMD GPU加速器，对RISC-V存算一体加速器支持有限。

#figure(
  image("./assets/Triton.jpg", width: 100%),
  caption: [
    Triton架构图
  ],
) <Triton>

- XLA @XLA23 是谷歌于2017年开始开发的一种深度学习领域编译器。其接受来自PyTorch、TensorFlow和JAX等ML框架的模型，在中间优化层级，XLA包括整体模型优化，如简化代数表达式、优化内存数据布局和改进调度等等。但是XLA主要针对TensorFlow优化，对其他框架的支持可能需要额外的工作；同时，其主要面向GPU和谷歌的TPU，其中间表示为深度学习算子级别的抽象，使其难以拓展到RISC-V存算一体加速器。

#figure(
  image("./assets/XLA.png", width: 50%),
  caption: [
    XLA架构图
  ],
) <XLA>

- IREE @IREE19 是一个开源的通用编译和运行时框架，由谷歌发布于2019年。通过输入高层次的机器学习模型，IREE为各种硬件生成优化的可执行代码。在中间优化层级，IREE利用MLIR进行多阶段优化，确保模型在目标平台上高效运行。IREE提供了高性能的编译器后端，硬件抽象层允许轻松添加对新硬件的支持，但是IREE框架主要针对深度学习模型进行端到端的优化，而缺少统一编程模型。

#figure(
  image("./assets/IREE.svg", width: 100%),
  caption: [
    IREE架构图
  ],
) <IREE>

- AKG @AKG21 是一个由华为主导开发的深度学习编译器框架。AKG可以接收来自ML框架的模型，生成针对特定硬件优化的内核。在中间优化层级，AKG通过自动性能调优工具，自动生成优化的内核。AKG提供了自动化的调优过程，可以显著提高性能，但是其主要支持华为的昇腾系列AI加速器和英伟达的GPU，对RISC-V存算一体异构芯片支持并不友好。

#figure(
  image("./assets/AKG.png", width: 100%),
  caption: [
    AKG架构图
  ],
) <AKG>

= 理论与实践上的意义

== 理论意义

该项目的的理论意义在于探索如何通过解耦软件操作和硬件配置来提高人工智能应用的开发效率和部署便捷性。同时，通过深入研究LLVM编译器和RISC-V存算芯片的特性，探索新的动态编译优化方法，以适应人工智能应用动态变化和未来存算芯片架构特征的需求，更好地实现应用算子的自动映射和正确指令流生成，从而协调计算部件，挖掘芯片内部计算并行性。

== 实践意义

该项目的实际意义在于解决当前存算芯片异构化、碎片化现状下开发者面临的挑战，为RISC-V存算芯片提供有力的编译支持。通过修改LLVM编译器，实现对存算指令的支持，可以为存算一体芯片的开发和应用提供更高效的解决方案。该项目的实施将促进存算芯片的发展和应用，推动存算技术的创新和进步，提升AI应用的性能和效率，为实现存算一体架构的潜力提供重要支持。

= 需要解决的关键理论问题和实际问题

== 理论问题

如何为解耦后的RISC-V生态提供编译支持，并允许编译器可以将应用算子自动映射到具有不同IP设计的加速部件，根据不同芯片架构特征生成正确的指令流来协调各个计算部件，挖掘芯片内部的计算并行性。

== 实际问题

如何将应用算子自动映射到具有不同IP设计的加速部件，同时根据不同芯片架构特征如何生成正确的指令流来协调各个计算部件，来挖掘芯片内部的计算并行性。

= 基本方法、实验方案及技术路线的可行性验证

== 基本方法

本项目将面向RISC-V存算芯片修改编译器，实现对存算指令的支持。通过深入研究LLVM编译器的架构和工作原理，分析RISC-V存算一体芯片的特性，探索如何在LLVM中添加对RISC-V存算模拟器的支持。这包括但不限于对指令集的扩展、内存模型的适配以及优化策略的调整等，以实现应用算子的自动映射和正确指令流的生成，从而更好地协调计算部件，挖掘芯片内部的计算并行性，为RISC-V存算一体芯片提供有力的编译支持。

== 实验方案及技术路线

该项目面向RISC-V存算一体芯片修改LLVM编译器，并将其和底层RISC-V指令映射，以便在计算、计算部件协同、通信、存储互联、数据类型等多个角度对硬件特征进行抽象。 具体实验方案如下：

+ 项目准备
  - 文献调研：深入学习LLVM编译器架构、RISC-V指令集及存算一体芯片（CIM）的相关文献，了解现有的研究成果和技术瓶颈。
  - 工具环境搭建：配置LLVM开发环境，获取并熟悉RISC-V的开发工具链，安装必要的模拟器和调试工具。

+ LLVM编译器架构分析与扩展
  - LLVM架构理解：详细分析LLVM的前端、中端和后端的工作流程，理解其插件机制和扩展接口。
  - 指令集扩展：根据RISC-V CIM芯片的存算操作需求，设计并实现新的指令集扩展。包括定义新的指令语义、编码格式以及相关的操作数。
  - 后端开发：在LLVM的RISC-V后端中集成新增的存算指令。实现指令的生成、调度和优化，包括i在汇编生成和机器码生成阶段的适配。

+ 内存模型适配
  - 存储器体系结构分析：研究RISC-V CIM芯片的内存架构，理解其数据存储与计算的交互方式。
  - 内存模型修改：调整LLVM的内存模型以适应CIM芯片的特点，确保数据在存储与计算单元之间高效传输。

+ 优化策略调整
  - 并行计算挖掘：分析CIM芯片的计算并行性，设计针对性的优化策略，如指令级并行、数据流优化等。
  - 自动算子映射：开发自动映射机制，将高层次的算子（如矩阵乘法、卷积等）高效地映射到CIM芯片的存算指令，优化计算性能和能耗。
  - 优化Pass开发：在LLVM的优化阶段引入新的Pass，针对CIM架构进行特定的代码优化，如循环展开、向量化等。

+ 模拟器集成与测试
  - 存算模拟器继承：集成支持存算指令的RISC-V模拟器，确保新增指令能够在模拟环境中正确执行。
  - 测试用例设计：编写多样化的测试用例，覆盖新增指令、内存模型和优化策略，验证编译器的正确性和性能提升。
  - 性能评估：通过对比实验，评估修改后的LLVM编译器在CIM架构上的性能表现，包括执行速度、能耗和资源利用率等指标。

+ 文档撰写与总结
  - 实验记录与分析：详细记录实验过程、问题与解决方案，并对实验结果进行分析。
  - 报告撰写：整理项目成果，撰写本科毕业设计报告，涵盖研究背景、方法、实验结果与结论。

#v(1em)

== 可行性分析

+ 技术方案可行
  - LLVM的灵活性：LLVM作为一个模块化、可扩展的编译器基础设施，具备良好的扩展能力，能够支持新增指令集和优化策略的集成。
  - RISC-V的开放性：RISC-V指令集架构公开透明，易于理解和扩展，适合作为研究与开发的平台。
+ 资源与工具支持
  - 丰富的开发资源：LLVM和RISC-V均有完善的文档、社区支持和开源资源，有助于加快开发进度和解决技术难题。
  - 现有模拟器与工具链：本课题组已有基于RISC-V开发的SRAM存算一体FPGA模拟器，通过RISC-V扩展指令实现了矩阵乘操作。
+ 项目可分阶段进行
  - 模块化开发：项目可以分为指令集扩展、内存模型修改、优化策略调整等多个独立模块进行，降低开发复杂度，便于逐步实现和调试。
  - 渐进式集成与测试：通过逐步集成新增功能并进行测试，确保每个阶段的功能正确性和稳定性，降低整体项目风险。

#v(1em)

= 应具备的条件及已具备的条件，可能遇到的困难与问题和解决措施

== 开展研究应具备的条件

课题组成员应熟练掌握编译器的相关实现、异构编程以及存算芯片的相关知识，需要对MLIR的设计方式较为熟悉。

== 已具备的条件

- 课题组成员在2024年全国大学生系统能力大赛编译系统实现赛中获得二等奖，熟悉编译器的基本理论和相关实现；
- 课题组成员具备一定的编程能力，能够使用C++、Python等语言进行编译器的开发。

#v(1em)

== 可能遇到的困难与问题和解决措施

- 异构编程上手存在一定的难度，要加强理论学习，后续在老师的指导下，以项目为驱动，学习异构编程。

#v(1em)

= 论文研究的进展计划

+ 2024.11.01 \~ 2024.12.20：调研AI编译器、存算一体芯片等相关理论和研究现状，形成调研报告；
+ 2024.12.21 \~ 2025.01.19：配置LLVM开发环境，熟悉RISC-V开发工具链，并安装必要的模拟器和调试工具，撰写本科毕业设计开题报告；
+ 2025.01.20 \~ 2025.03.30：分析LLVM编译器架构同时进行扩展，并进行内存模型适配，准备中期检查相关材料；
+ 2025.04.01 \~ 2025.04.20：调整编译器优化策略并进行模拟器集成与测试，验证编译器的正确性和性能提升；
+ 2025.04.21 \~ 2025.06.10：梳理总结研究成果，撰写毕业设计报告，准备毕业论文答辩工作。

#v(1em)

= 课题所需器材、设备清单

- GPU
- RISC-V存算一体模拟器

#pagebreak()

= 参考文献

#bibliography("references.bib", style: "gb-7714-2005-numeric", title: none)